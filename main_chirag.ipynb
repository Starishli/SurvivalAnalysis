{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "CUDA = torch.cuda.is_available()\n",
    "print(CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from lifelines.utils import concordance_index \n",
    "import sys\n",
    "from torch import nn\n",
    "import survival_analysis_chirag\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import network\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "ds = pd.read_csv('whas500.csv',sep=',')\n",
    "train = ds[:400]\n",
    "validation = ds[400:]\n",
    "\n",
    "x = train[['age', 'gender', 'bmi', 'chf', 'miord']]\n",
    "e = train['fstat']\n",
    "t = train['lenfol']\n",
    "\n",
    "x = torch.from_numpy(x.as_matrix()).float()\n",
    "e = torch.from_numpy(e.as_matrix()).float()\n",
    "t = torch.from_numpy(t.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CUDA:\n",
    "    x = x.cuda()\n",
    "    e = e.cuda()\n",
    "    t = t.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)\n",
    "#         m.weight.data.fill_(0)\n",
    "#         m.bias.data.fill_(1)\n",
    "\n",
    "def init_weights_for_cox(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.data.fill_(0)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, e, t, CUDA, optimizer, n_epochs):\n",
    "\n",
    "    # Initialize Metrics\n",
    "    c_index = []\n",
    "    valid_c_index = []\n",
    "\n",
    "    risk_set = []\n",
    "    for i in range(len(t)):\n",
    "        temp = []\n",
    "        for j in range(len(t)):\n",
    "            if t[j] >= t[i]:\n",
    "                temp.append(j)\n",
    "        risk_set.append(temp)\n",
    "    \n",
    "    start = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # print(\"x: \", x)\n",
    "        outputs = model(x)\n",
    "\n",
    "        loss = negative_log_likelihood(outputs, e, risk_set, CUDA)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        print(loss.cpu().data.numpy())\n",
    "        \n",
    "        ci_train = get_concordance_index(outputs, t, e)\n",
    "        c_index.append(ci_train)\n",
    "        torch.cuda.empty_cache()\n",
    "                   \n",
    "        print('Finished Training with %d iterations in %0.2fs' % (epoch + 1, time.time() - start))\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['c-index'] = c_index\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(risk, E, risk_set, CUDA):\n",
    "    new_risk = []\n",
    "    for i in range(len(risk_set)):\n",
    "        new_risk.append(risk[risk_set[i]])\n",
    "        \n",
    "    log_risk = []\n",
    "    for i in range(len(new_risk)):\n",
    "        temp = torch.logsumexp(new_risk[i], 0)\n",
    "        log_risk.append(temp)\n",
    "\n",
    "    uncensored_likelihood = torch.transpose(risk, 0, 1) - torch.tensor(log_risk)\n",
    "    censored_likelihood = uncensored_likelihood * E\n",
    "    num_observed_events = torch.sum(E)\n",
    "    neg_likelihood = -torch.sum(censored_likelihood)# / num_observed_events\n",
    "    return neg_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concordance_index(x, t, e, **kwargs):\n",
    "    x = x.detach().cpu().numpy()\n",
    "    t = t.detach().cpu().numpy()\n",
    "    e = e.detach().cpu().numpy()\n",
    "    computed_hazard = np.exp(x)\n",
    "\n",
    "    return concordance_index(t,-1*computed_hazard,e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPH model\n",
      "1135.8035\n",
      "Finished Training with 1 iterations in 0.02s\n",
      "1133.6571\n",
      "Finished Training with 2 iterations in 0.04s\n",
      "1131.5813\n",
      "Finished Training with 3 iterations in 0.07s\n",
      "1129.4191\n",
      "Finished Training with 4 iterations in 0.09s\n",
      "1127.3672\n",
      "Finished Training with 5 iterations in 0.11s\n",
      "1125.4402\n",
      "Finished Training with 6 iterations in 0.13s\n",
      "1123.613\n",
      "Finished Training with 7 iterations in 0.15s\n",
      "1121.9609\n",
      "Finished Training with 8 iterations in 0.19s\n",
      "1120.4762\n",
      "Finished Training with 9 iterations in 0.20s\n",
      "1119.0332\n",
      "Finished Training with 10 iterations in 0.22s\n",
      "1117.5244\n",
      "Finished Training with 11 iterations in 0.26s\n",
      "1116.1117\n",
      "Finished Training with 12 iterations in 0.29s\n",
      "1114.8391\n",
      "Finished Training with 13 iterations in 0.31s\n",
      "1113.7388\n",
      "Finished Training with 14 iterations in 0.33s\n",
      "1112.7856\n",
      "Finished Training with 15 iterations in 0.37s\n",
      "1112.0177\n",
      "Finished Training with 16 iterations in 0.41s\n",
      "1111.431\n",
      "Finished Training with 17 iterations in 0.42s\n",
      "1111.0688\n",
      "Finished Training with 18 iterations in 0.45s\n",
      "1110.8485\n",
      "Finished Training with 19 iterations in 0.48s\n",
      "1110.7336\n",
      "Finished Training with 20 iterations in 0.51s\n",
      "1110.8055\n",
      "Finished Training with 21 iterations in 0.53s\n",
      "1111.0236\n",
      "Finished Training with 22 iterations in 0.56s\n",
      "1111.3577\n",
      "Finished Training with 23 iterations in 0.58s\n",
      "1111.7946\n",
      "Finished Training with 24 iterations in 0.60s\n",
      "1112.2991\n",
      "Finished Training with 25 iterations in 0.62s\n",
      "1112.939\n",
      "Finished Training with 26 iterations in 0.64s\n",
      "1113.6512\n",
      "Finished Training with 27 iterations in 0.66s\n",
      "1114.3175\n",
      "Finished Training with 28 iterations in 0.68s\n",
      "1115.0339\n",
      "Finished Training with 29 iterations in 0.70s\n",
      "1115.8385\n",
      "Finished Training with 30 iterations in 0.73s\n",
      "1116.7366\n",
      "Finished Training with 31 iterations in 0.75s\n",
      "1117.6597\n",
      "Finished Training with 32 iterations in 0.76s\n",
      "1118.7008\n",
      "Finished Training with 33 iterations in 0.78s\n",
      "1119.8477\n",
      "Finished Training with 34 iterations in 0.80s\n",
      "1121.0645\n",
      "Finished Training with 35 iterations in 0.82s\n",
      "1122.3658\n",
      "Finished Training with 36 iterations in 0.83s\n",
      "1123.7281\n",
      "Finished Training with 37 iterations in 0.85s\n",
      "1125.1605\n",
      "Finished Training with 38 iterations in 0.88s\n",
      "1126.6398\n",
      "Finished Training with 39 iterations in 0.90s\n",
      "1128.1919\n",
      "Finished Training with 40 iterations in 0.92s\n",
      "1129.8223\n",
      "Finished Training with 41 iterations in 0.93s\n",
      "1131.5333\n",
      "Finished Training with 42 iterations in 0.95s\n",
      "1133.2494\n",
      "Finished Training with 43 iterations in 0.97s\n",
      "1134.9567\n",
      "Finished Training with 44 iterations in 0.99s\n",
      "1136.6975\n",
      "Finished Training with 45 iterations in 1.01s\n",
      "1138.4802\n",
      "Finished Training with 46 iterations in 1.03s\n",
      "1140.3188\n",
      "Finished Training with 47 iterations in 1.05s\n",
      "1142.2144\n",
      "Finished Training with 48 iterations in 1.07s\n",
      "1144.1992\n",
      "Finished Training with 49 iterations in 1.10s\n",
      "1146.2397\n",
      "Finished Training with 50 iterations in 1.12s\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For CPH, set cox argument as True\n",
    "print(\"CPH model\")\n",
    "n_in = x.shape[1]\n",
    "\n",
    "layers_sizes = [n_in, 48, 48, 1]\n",
    "\n",
    "# Construct Neural Network\n",
    "layers = []\n",
    "for i in range(len(layers_sizes)-2):\n",
    "    layers.append(nn.Linear(layers_sizes[i],layers_sizes[i+1]))\n",
    "    layers.append(nn.ReLU())\n",
    "\n",
    "layers.append(nn.Linear(layers_sizes[-2], layers_sizes[-1]))\n",
    "my_network = nn.Sequential(*layers)\n",
    "my_network.apply(init_weights)\n",
    "\n",
    "#optimizer = optimizer = torch.optim.SGD(my_network.parameters(), lr=learning_rate, momentum=momentum, weight_decay=L2_reg, nesterov=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(my_network.parameters(), lr=1e-4)\n",
    "my_network.train()\n",
    "if CUDA:\n",
    "    my_network.cuda()\n",
    "\n",
    "# If you have validation data, you can add it as the valid_dataloader parameter to the function\n",
    "n_epochs = 50\n",
    "metrics = train(my_network, x, e, t, CUDA, optimizer, n_epochs)\n",
    "print()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=5, out_features=48, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=48, out_features=48, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=48, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train C-Index: [0.2703059339410057, 0.272579630118354, 0.2750157331655129, 0.27830447227917743, 0.2824255466006212, 0.2871759475425811, 0.2919872510607199, 0.2990925516149333, 0.3064820641913153, 0.3148866197040135, 0.32398140441340667, 0.3349438681256217, 0.346738667045616, 0.36046204754461114, 0.3753222761322804, 0.3917456708418766, 0.409184108487789, 0.42576991006719583, 0.4435737631701821, 0.46005806045595726, 0.4750400941959845, 0.4893928013154956, 0.503258287825575, 0.5163929434215068, 0.5299742179094176, 0.5428652632006334, 0.5533405063034166, 0.5629225116222416, 0.5715706774396557, 0.5791428977445746, 0.5860248888527985, 0.5926226679388538, 0.5996264641994357, 0.6048437848921009, 0.6106904322052823, 0.6159077528979476, 0.6212671796016972, 0.625266448770783, 0.6290627093526057, 0.6328183682169756, 0.6358634970259242, 0.6388274223999675, 0.6415477374692949, 0.6433342130372115, 0.6458515195192757, 0.6476988976633712, 0.6493432672202034, 0.6508861324834041, 0.6521650865831625, 0.6536064475527315]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train C-Index:\", metrics['c-index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
