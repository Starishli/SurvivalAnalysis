{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable_1   Variable_2  Variable_3  Variable_4  Event  Time\n",
      "0            0           3           2         4.6      1    43\n",
      "1            0           2           0         1.6      0    52\n",
      "2            0           3           0         3.5      1    73\n",
      "3            0           3           1         5.1      0    51\n",
      "4            0           2           0         1.7      0    51\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import viz\n",
    "import torch\n",
    "from torch import nn\n",
    "import survival_analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import network\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# event_col is the header in the df that represents the 'Event / Status' indicator\n",
    "# time_col is the header in the df that represents the event time\n",
    "def dataframe_to_deepsurv_ds(df, event_col = 'Event', time_col = 'Time'):\n",
    "    # Extract the event and time columns as numpy arrays\n",
    "    e = df[event_col].values.astype(np.int32)\n",
    "    t = df[time_col].values.astype(np.float32)\n",
    "\n",
    "    # Extract the patient's covariates as a numpy array\n",
    "    x_df = df.drop([event_col, time_col], axis = 1)\n",
    "    x = x_df.values.astype(np.float32)\n",
    "    \n",
    "    # Return the deep surv dataframe\n",
    "    return {\n",
    "        'x' : x,\n",
    "        'e' : e,\n",
    "        't' : t\n",
    "    }\n",
    "\n",
    "class MyTrainDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, train_file_path, standardize=False):\n",
    "        self.train_df = pd.read_csv(train_file_path)\n",
    "        print(self.train_df.head())\n",
    "        # If the headers of the csv change, you can replace the values of \n",
    "        # 'event_col' and 'time_col' with the names of the new headers\n",
    "        # You can also use this function on your training dataset, validation dataset, and testing dataset\n",
    "        train_data = dataframe_to_deepsurv_ds(self.train_df, event_col = 'Event', time_col= 'Time')\n",
    "\n",
    "        self.x, self.e, self.t = train_data['x'], train_data['e'], train_data['t']\n",
    "        \n",
    "        if standardize:\n",
    "            offset = self.x.mean(axis = 0)\n",
    "            scale = self.x.std(axis = 0)\n",
    "            self.x = (self.x - offset) / scale\n",
    "        \n",
    "        # Sort Training Data for Accurate Likelihood\n",
    "        sort_idx = np.argsort(self.t)[::-1]\n",
    "        self.x = self.x[sort_idx]\n",
    "        self.e = self.e[sort_idx]\n",
    "        self.t = self.t[sort_idx]\n",
    "        \n",
    "        self.processed_count = 1\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.train_df.index)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        self.processed_count += 1\n",
    "        return self.x[i], self.e[i], self.t[i]\n",
    "#         return (torch.from_numpy(x), torch.from_numpy(e), torch.from_numpy(t))\n",
    "\n",
    "train_ds = MyTrainDataset('example_data.csv', True)\n",
    "train_loader = dataloader.DataLoader(train_ds, shuffle=False, batch_size=16,num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the dataset to \"DeepSurv\" format\n",
    "DeepSurv expects a dataset to be in the form:\n",
    "\n",
    "    {\n",
    "        'x': numpy array of float32\n",
    "        'e': numpy array of int32\n",
    "        't': numpy array of float32\n",
    "        'hr': (optional) numpy array of float32\n",
    "    }\n",
    "    \n",
    "You are providing me a csv, which I read in as a pandas dataframe. Then I convert the pandas dataframe into the DeepSurv dataset format above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_likelihood:  tensor(5.1479, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(9.5214, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(6.6618, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(3.4682, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(8.9888, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(9.1800, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(1.5888, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(3.9015, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(3.9355, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(2.0350, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(2.4757, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(9.0517, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(5.9786, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(2.9574, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(17.5902, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(7.6286, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(0.5422, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(16.0885, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(7.1062, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(8.1342, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(12.0273, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(16.9487, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(6.5452, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(10.9437, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(2.8642, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(4.1367, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(22.8136, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(2.8584, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(6.2151, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(4.2812, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(6.0051, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(8.4669, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(2.4327, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(3.7363, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(5.8432, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(13.4285, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(5.3840, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(6.1276, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(2.7926, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(22.8183, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(5.5386, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(13.0199, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(15.9411, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(20.4811, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(-0., device='cuda:0', grad_fn=<NegBackward>)\n",
      "Epoch: 1\tBatch: 50\tAvg-Loss: 7.0726\n",
      "neg_likelihood:  tensor(9.0320, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(16.8772, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(16.1789, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(8.5939, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(23.6492, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(12.2588, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(9.9826, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(7.3376, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(22.5555, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(16.5283, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(3.6025, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(7.1076, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(5.2810, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(1.3897, device='cuda:0', grad_fn=<NegBackward>)\n",
      "neg_likelihood:  tensor(10.5115, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 1 iterations in 0.70s\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "L2_reg = 1e-05\n",
    "batch_norm = True\n",
    "dropout = 0.4\n",
    "hidden_layers_sizes = [25, 25]\n",
    "learning_rate = 1e-05\n",
    "lr_decay = 0.001\n",
    "momentum = 0.9\n",
    "n_in = train_ds.x.shape[1]\n",
    "standardize = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "my_network = network.DeepSurv(n_in, hidden_layers_sizes=hidden_layers_sizes, dropout=dropout, batch_norm=batch_norm, momentum=0.1)\n",
    "my_network.apply(init_weights)\n",
    "# network.load_state_dict(torch.load(\"model_99.pt\"))\n",
    "\n",
    "optimizer = optimizer = torch.optim.SGD(my_network.parameters(), lr=learning_rate, momentum=momentum, weight_decay=L2_reg, nesterov=True)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,1,gamma=lr_decay,last_epoch=-1)\n",
    "my_network.train()\n",
    "\n",
    "my_network.to(device)\n",
    "\n",
    "# If you have validation data, you can add it as the valid_dataloader parameter to the function\n",
    "metrics = survival_analysis.train(my_network, train_loader, device=device, optimizer=optimizer, scheduler=exp_lr_scheduler, n_epochs=n_epochs)\n",
    "print()\n",
    "# print(my_network.layers[0].weight)\n",
    "# print(my_network.layers[0].bias)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'c-index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-62c5bd9000d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the final metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train C-Index:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c-index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print('Valid C-Index: ',metrics['valid_c-index'][-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Plot the training / validation curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'c-index'"
     ]
    }
   ],
   "source": [
    "# Print the final metrics\n",
    "print('Train C-Index:', metrics['c-index'][-1])\n",
    "# print('Valid C-Index: ',metrics['valid_c-index'][-1])\n",
    "\n",
    "# Plot the training / validation curves\n",
    "viz.plot_log(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
