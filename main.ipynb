{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import viz\n",
    "import torch\n",
    "from torch import nn\n",
    "import survival_analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import network\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# event_col is the header in the df that represents the 'Event / Status' indicator\n",
    "# time_col is the header in the df that represents the event time\n",
    "def dataframe_to_deepsurv_ds(df, event_col = 'Event', time_col = 'Time'):\n",
    "    # Extract the event and time columns as numpy arrays\n",
    "    e = df[event_col].values.astype(np.int32)\n",
    "    t = df[time_col].values.astype(np.float32)\n",
    "\n",
    "    # Extract the patient's covariates as a numpy array\n",
    "    x_df = df.drop([event_col, time_col], axis = 1)\n",
    "    x = x_df.values.astype(np.float32)\n",
    "    \n",
    "    # Return the deep surv dataframe\n",
    "    return {\n",
    "        'x' : x,\n",
    "        'e' : e,\n",
    "        't' : t\n",
    "    }\n",
    "\n",
    "class MyTrainDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, train_file_path, standardize=False):\n",
    "        self.train_df = pd.read_csv(train_file_path)\n",
    "        print(len(self.train_df.index))\n",
    "        # If the headers of the csv change, you can replace the values of \n",
    "        # 'event_col' and 'time_col' with the names of the new headers\n",
    "        # You can also use this function on your training dataset, validation dataset, and testing dataset\n",
    "        train_data = dataframe_to_deepsurv_ds(self.train_df, event_col = 'Event', time_col= 'Time')\n",
    "\n",
    "        self.x, self.e, self.t = train_data['x'], train_data['e'], train_data['t']\n",
    "        \n",
    "        if standardize:\n",
    "            offset = self.x.mean(axis = 0)\n",
    "            scale = self.x.std(axis = 0)\n",
    "            self.x = (self.x - offset) / scale\n",
    "        \n",
    "        # Sort Training Data for Accurate Likelihood\n",
    "        sort_idx = np.argsort(self.t)[::-1]\n",
    "        self.x = self.x[sort_idx]\n",
    "        self.e = self.e[sort_idx]\n",
    "        self.t = self.t[sort_idx]\n",
    "        \n",
    "        self.processed_count = 1\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.train_df.index)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        self.processed_count += 1\n",
    "        return self.x[i], self.e[i], self.t[i]\n",
    "#         return (torch.from_numpy(x), torch.from_numpy(e), torch.from_numpy(t))\n",
    "\n",
    "train_ds = MyTrainDataset('example_data.csv', True)\n",
    "train_loader = dataloader.DataLoader(train_ds, shuffle=False, batch_size=len(train_ds),num_workers=8)\n",
    "print(len(train_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the dataset to \"DeepSurv\" format\n",
    "DeepSurv expects a dataset to be in the form:\n",
    "\n",
    "    {\n",
    "        'x': numpy array of float32\n",
    "        'e': numpy array of int32\n",
    "        't': numpy array of float32\n",
    "        'hr': (optional) numpy array of float32\n",
    "    }\n",
    "    \n",
    "You are providing me a csv, which I read in as a pandas dataframe. Then I convert the pandas dataframe into the DeepSurv dataset format above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)\n",
    "        \n",
    "def init_weights_for_cox(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.data.fill_(0)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSurv model\n",
      "neg_likelihood:  tensor(1477.7983, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 1 iterations in 0.33s\n",
      "neg_likelihood:  tensor(1336.0844, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 2 iterations in 0.66s\n",
      "neg_likelihood:  tensor(1338.0771, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 3 iterations in 0.98s\n",
      "neg_likelihood:  tensor(1331.1168, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 4 iterations in 1.32s\n",
      "neg_likelihood:  tensor(1325.8162, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 5 iterations in 1.64s\n",
      "neg_likelihood:  tensor(1333.8635, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 6 iterations in 1.96s\n",
      "neg_likelihood:  tensor(1338.8193, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 7 iterations in 2.27s\n",
      "neg_likelihood:  tensor(1336.8557, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 8 iterations in 2.61s\n",
      "neg_likelihood:  tensor(1326.6046, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 9 iterations in 2.93s\n",
      "neg_likelihood:  tensor(1333.2085, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 10 iterations in 3.26s\n",
      "neg_likelihood:  tensor(1325.1064, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 11 iterations in 3.60s\n",
      "neg_likelihood:  tensor(1323.8987, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 12 iterations in 3.91s\n",
      "neg_likelihood:  tensor(1318.4062, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 13 iterations in 4.23s\n",
      "neg_likelihood:  tensor(1329.1357, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 14 iterations in 4.56s\n",
      "neg_likelihood:  tensor(1338.8849, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 15 iterations in 4.88s\n",
      "\n",
      "CPH model\n",
      "neg_likelihood:  tensor(1359.9502, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 1 iterations in 0.33s\n",
      "neg_likelihood:  tensor(1300.9178, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 2 iterations in 0.68s\n",
      "neg_likelihood:  tensor(1300.9091, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 3 iterations in 0.98s\n",
      "neg_likelihood:  tensor(1300.9092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 4 iterations in 1.30s\n",
      "neg_likelihood:  tensor(1300.9092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 5 iterations in 1.68s\n",
      "neg_likelihood:  tensor(1300.9092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 6 iterations in 2.05s\n",
      "neg_likelihood:  tensor(1300.9092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 7 iterations in 2.37s\n",
      "neg_likelihood:  tensor(1300.9092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 8 iterations in 2.70s\n",
      "neg_likelihood:  tensor(1300.9092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 9 iterations in 3.01s\n",
      "neg_likelihood:  tensor(1300.9092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 10 iterations in 3.34s\n",
      "neg_likelihood:  tensor(1300.9092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 11 iterations in 3.66s\n",
      "neg_likelihood:  tensor(1300.9092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 12 iterations in 3.97s\n",
      "neg_likelihood:  tensor(1300.9092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 13 iterations in 4.29s\n",
      "neg_likelihood:  tensor(1300.9092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 14 iterations in 4.62s\n",
      "neg_likelihood:  tensor(1300.9092, device='cuda:0', grad_fn=<NegBackward>)\n",
      "Finished Training with 15 iterations in 4.95s\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "L2_reg = 1e-05\n",
    "batch_norm = True\n",
    "dropout = 0.4\n",
    "hidden_layers_sizes = [25, 25]\n",
    "learning_rate = 1e-03\n",
    "lr_decay = 0.001\n",
    "momentum = 0.9\n",
    "n_in = train_ds.x.shape[1]\n",
    "standardize = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"DeepSurv model\")\n",
    "my_network = network.DeepSurv(n_in, hidden_layers_sizes=hidden_layers_sizes, dropout=dropout, batch_norm=batch_norm, momentum=0.1)\n",
    "my_network.apply(init_weights)\n",
    "# network.load_state_dict(torch.load(\"model_99.pt\"))\n",
    "\n",
    "optimizer = optimizer = torch.optim.SGD(my_network.parameters(), lr=learning_rate, momentum=momentum, weight_decay=L2_reg, nesterov=True)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,1,gamma=lr_decay,last_epoch=-1)\n",
    "my_network.train()\n",
    "\n",
    "my_network.to(device)\n",
    "\n",
    "# If you have validation data, you can add it as the valid_dataloader parameter to the function\n",
    "metrics = survival_analysis.train(my_network, train_loader, device=device, optimizer=optimizer, scheduler=exp_lr_scheduler, n_epochs=n_epochs)\n",
    "print()\n",
    "# print(my_network.layers[0].weight)\n",
    "# print(my_network.layers[0].bias)\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "# For CPH, set cox argument as True\n",
    "print(\"CPH model\")\n",
    "my_network = network.DeepSurv(n_in, hidden_layers_sizes=[], dropout=dropout, batch_norm=batch_norm, momentum=0.1, cox=True)\n",
    "my_network.apply(init_weights_for_cox)\n",
    "# network.load_state_dict(torch.load(\"model_99.pt\"))\n",
    "\n",
    "optimizer = optimizer = torch.optim.SGD(my_network.parameters(), lr=learning_rate, momentum=momentum, weight_decay=L2_reg, nesterov=True)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,1,gamma=lr_decay,last_epoch=-1)\n",
    "my_network.train()\n",
    "\n",
    "my_network.to(device)\n",
    "\n",
    "# If you have validation data, you can add it as the valid_dataloader parameter to the function\n",
    "metrics = survival_analysis.train(my_network, train_loader, device=device, optimizer=optimizer, scheduler=exp_lr_scheduler, n_epochs=n_epochs)\n",
    "print()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'c-index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-62c5bd9000d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the final metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train C-Index:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c-index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print('Valid C-Index: ',metrics['valid_c-index'][-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Plot the training / validation curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'c-index'"
     ]
    }
   ],
   "source": [
    "# Print the final metrics\n",
    "print('Train C-Index:', metrics['c-index'][-1])\n",
    "# print('Valid C-Index: ',metrics['valid_c-index'][-1])\n",
    "\n",
    "# Plot the training / validation curves\n",
    "viz.plot_log(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
